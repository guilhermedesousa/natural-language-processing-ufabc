{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 05 [LangChain + Grandes Modelos de Linguagem + API]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 05** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/C1oUi1FKTZ4W9fNdA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **10/12 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnIArN0QY-Ek"
      },
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Carlos Henrique Alencar Lima RA:11202021040`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Guilherme de Sousa Santos RA:11201921175`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`José Roberto de Oliveira RA:11201920397`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbYD2mw8y4CN"
      },
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UlblxFxzDV-"
      },
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*). Preferencialmente, usar um modelo gratuito. Cada modelo pode ser escolhido por até 4 equipes.\n",
        "\n",
        ">\n",
        "\n",
        "Uma lista de LLMs está disponível em:\n",
        "\n",
        "> https://integrations.langchain.com/llms\n",
        "> https://python.langchain.com/docs/integrations/llms/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVpiVhzn3QqE"
      },
      "source": [
        "**Modelos da Hugging Face:**\n",
        "\n",
        "* Mistral Base: modelo promissor.\n",
        "\n",
        "> https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
        "\n",
        "* Mistral Quantizado: mais leve. Pode ser um pouco mais difícil de configurar, mas deve ocupar menos memória.\n",
        "\n",
        "> https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\n",
        "\n",
        "* Mistral Lite da Amazon: pode ter desempenho melhor.\n",
        "\n",
        "> https://huggingface.co/amazon/MistralLite\n",
        "\n",
        "* Llama 2 7B: modelo da Meta melhorado.\n",
        "\n",
        "> https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "\n",
        "* Llama 2 7b 32k: contexto maior pelo mesmo tamanho.\n",
        "\n",
        "> https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct\n",
        "\n",
        "* Galactica: para artigos científicos\n",
        "\n",
        "> https://huggingface.co/facebook/galactica-6.7b\n",
        "\n",
        "* Alpaca: alternativo ao Llama\n",
        "\n",
        "> https://huggingface.co/chavinlo/alpaca-native\n",
        "\n",
        "> https://huggingface.co/spaces/tloen/alpaca-lora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRuAiSr05Ayt"
      },
      "source": [
        "**Lista de Modelos Interessantes:**\n",
        "\n",
        "> https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html\n",
        "\n",
        "* Vicuna:\n",
        "> https://huggingface.co/lmsys/vicuna-7b-v1.5-16k\n",
        "\n",
        "* Openchat kit:\n",
        "> https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\n",
        "\n",
        "* Meta OPT:\n",
        "> https://huggingface.co/facebook/opt-1.3b\n",
        "\n",
        "* Google Flan:\n",
        "> https://huggingface.co/google/flan-t5-base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q3mhqda5WP1"
      },
      "source": [
        "**APIs:**\n",
        "\n",
        "* GPT4ALL: tenta ser um chatGPT aberto\n",
        "> https://python.langchain.com/docs/integrations/llms/gpt4all\n",
        "\n",
        "* YandexGPT: da empresa russa que criou um modelo de *Machine Learning* clássico muito bom, o CatBoost.\n",
        "> https://python.langchain.com/docs/integrations/llms/yandex\n",
        "\n",
        "* Anthropic: empresa forte concorrente da OpenAi.\n",
        "> https://python.langchain.com/docs/integrations/chat/anthropic\n",
        "\n",
        "* Gorilla: pipeline para geração de código\n",
        " > https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO6XMjHx58u9"
      },
      "source": [
        "**IMPORTANTE**: todo esse levantamento e comentários foram feitos pelo aluno  **Bruno Sanches Rodrigues**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AkE6iW0c3o"
      },
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**: Mistral 7B\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**: https://huggingface.co/docs/transformers/main/model_doc/mistral\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**Site oficial (GitHub)**: https://github.com/mistralai/mistral-src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2oo8GtK0xSO"
      },
      "source": [
        "**IMPORTANTE**: não pode ser o modelo da `OpenAI`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yExhaebs-nD"
      },
      "source": [
        "### **API**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJM_qhEZRy6"
      },
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**: Dados financeiros\n",
        "\n",
        "**Site oficial**: https://brapi.dev/\n",
        "\n",
        "**Link para a documentação oficial**: https://brapi.dev/docs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTODq98Myt_u"
      },
      "source": [
        "**IMPORTANTE**: não é necessário usar a mesma **API** da `ATIVIDADE PRÁTICA 03`. Cada **API** pode ser usada por até 4 equipes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXTwkiiGs2BV"
      },
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso do framework **`LangChain`** (obrigatório) e de um **LLM** aplicando, no mínimo, uma técnica de PLN. A técnica pode ser aplicada em qualquer córpus. Também é obrigatório usar uma **API** da `ATIVIDADE PRÁTICA 03`. A **API** pode ser usada tanto para obter os dados quanto para disponibilizar os resultados.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1cOL7zVNffqmliuv23zFm1UJjhEXTdp1Zm5EyAJmhiKg/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Lista de APIs:**\n",
        "\n",
        "\n",
        "* YouTube\n",
        "* LinkedIn\n",
        "* Twitter (X)\n",
        "* Facebook\n",
        "* Instagram\n",
        "* Medium\n",
        "* Reddit\n",
        "* TikTok\n",
        "* GitHub\n",
        "* Pinterest\n",
        "* Telegram\n",
        "* Dados financeiros\n",
        "* Notícias\n",
        "* Mercado de Ações\n",
        "* Dados financeiros\n",
        "* SMS\n",
        "* OpenAlex\n",
        "* Whisper (OpenAI)\n",
        "* Discord\n",
        "* Slack\n",
        "* Chuck Norris Jokes\n",
        "* Wikipedia\n",
        "* Last.fm\n",
        "* New York Times\n",
        "* Nasdaq Data Link\n",
        "* Yahoo! Finance\n",
        "* Twilio SendGrid Mail Send\n",
        "* Spotify\n",
        "* Awesome API\n",
        "* Google Books API\n",
        "* Mercado Livre API\n",
        "\n",
        ">\n",
        "\n",
        "**PLANILHA DA ATIVIDADE PRÁTICA 03:**\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1-Q1szJ3UmoE2_3LtcRQyqid5fPIcnpsR3XAPnoxLj2o/edit?usp=sharing\n",
        "\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWsBYQNtxmum"
      },
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iHdx4BXYruQ"
      },
      "source": [
        "Serão considerados como critérios de avaliação os segunintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API**\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhwdrMp123Xx"
      },
      "source": [
        "**IMPORTANTE**: todo o código do notebook deve ser executado. Código sem execução não será considerado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw09lujGvfjc"
      },
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9qpYUFM1rgy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDcru7Yq1rg0"
      },
      "source": [
        "## API BRAPI\n",
        "\n",
        "#### OBS: Uma nova atualização na API indisponibilizou o uso de várias ferramentas que usamos anteriormente, deixando somente a consulta a Ações, BDRs e Fundos imoboliários. Desta forma, deixamos somente uma função"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooFohZ1N1rg0"
      },
      "source": [
        "![Captura%20de%20tela%20de%202023-12-11%2019-56-44.png](attachment:Captura%20de%20tela%20de%202023-12-11%2019-56-44.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5aERzPZ1rg1"
      },
      "source": [
        "#### Autenticação\n",
        "Nesta etapa, vamos adicionar as variáveis para verificar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "outputs": [],
      "source": [
        "api_base_url = \"https://brapi.dev/api\"\n",
        "token = 'nLCTAb6KMPfGejfVANUTFR'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Bo-wUr1rg1"
      },
      "source": [
        "**Obter informação sobre uma ação específica**\n",
        "\n",
        "A seguinte célula de código cria uma função que utiliza o endpoint `{/quote/tickers}` para buscar a cotação algum ativo. Ela obtém dados atualizados e precisos sobre este ativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma4nXseG1rg2"
      },
      "outputs": [],
      "source": [
        "def get_current_stock_price(ticker: str):\n",
        "    url_q = api_base_url + '/quote/' + ticker.lower()\n",
        "    params = {\n",
        "        'range': '5d',\n",
        "        'interval': '1d',\n",
        "        'fundamental': 'true',\n",
        "        'dividends': 'false',\n",
        "        'token': token\n",
        "    }\n",
        "    try:\n",
        "        requisicao = requests.get(url_q, params=params)\n",
        "        requisicao.raise_for_status()  # Verificar se há erros na requisição\n",
        "\n",
        "        data = requisicao.json()\n",
        "        return json.dumps(data)\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWxfb99W1rg2"
      },
      "source": [
        "**Modelo**\n",
        "\n",
        "O modelo que estamos trabalhando é o Mistral 7B em conjunto com o Llama.cpp, para orquestração do modelo e adição de funções step-by-step. Além disso, fica muito mais fácil acessar e trabalhar com modelos locais, além da velocidade devido ao funcionamento em C++"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCWIOmjk1rg3"
      },
      "outputs": [],
      "source": [
        "from llama_cpp import Llama\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaQ5ddcY1rg3"
      },
      "source": [
        "Vamos criar o prompt. Todas as operações receberão o input em português, traduzidos para o inglês o qual performa muito melhor, e retorna o resultado em português."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KryfeBE51rg4"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rw04evv1rg4"
      },
      "outputs": [],
      "source": [
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ol-pV4Y1rg4"
      },
      "source": [
        "A variável **n_gpu_layers** é para atribuir a quantidade de camadas a serem utilizadas ao executar o modelo na placa de vídeo. Valor deve ser alterado conforme a quantidade de VRAM da placa de vídeo.\n",
        "\n",
        "A varíavel **n_batch** é para os batchs. Também deve ser alterado conforme a VRAM da placa de vídeo.\n",
        "\n",
        "A varíavel **n_ctx** é a quantidade de tokens que podem ser trabalhados. Também deve ser alterado conforme a VRAM da placa de vídeo.\n",
        "\n",
        "O modelo que é utilizado como base é o mistral 7b. Contudo, foi realizado o download do .gguf direto do diretório do The Bloke no Hugging Face, com intuíto de melhorar o tempo e acesso ao modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXIaOAzl1rg5",
        "outputId": "a16dc6ea-81d4-4863-a520-1db740324786"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from openhermes-2.5-mistral-7b.Q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  4096, 32002,     1,     1 ]\n",
            "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  290:                    output.weight q8_0     [  4096, 32002,     1,     1 ]\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = teknium_openhermes-2.5-mistral-7b\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32002\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = mostly Q8_0\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 7.17 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name   = teknium_openhermes-2.5-mistral-7b\n",
            "llm_load_print_meta: BOS token = 1 '<s>'\n",
            "llm_load_print_meta: EOS token = 32000 '<|im_end|>'\n",
            "llm_load_print_meta: UNK token = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token = 0 '<unk>'\n",
            "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
            "llm_load_tensors: mem required  = 7338.76 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_new_context_with_model: kv self size  =  256.00 MiB\n",
            "llama_build_graph: non-view tensors processed: 740/740\n",
            "llama_new_context_with_model: compute buffer total size = 315.07 MiB\n",
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "n_gpu_layers = 40\n",
        "n_batch = 1024\n",
        "n_ctx = 2048\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"openhermes-2.5-mistral-7b.Q8_0.gguf\",\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    callback_manager=callback_manager,\n",
        "    n_ctx = n_ctx,\n",
        "    verbose=True,  # Verbose is required to pass to the callback manager\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN2Jmnoi1rg7"
      },
      "source": [
        "Nesta parte do código, iremos criar a ferramenta de uso para o agente. Como a Brapi disponibiliza apenas um uso, então podemos trabalhar na mesma função."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bonuqpOx1rg7"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "\n",
        "get_current_stock_price = Tool.from_function(\n",
        "    name = \"get_current_stock_price\",\n",
        "    description = \"\"\"\n",
        "        Useful when you want to check performance of the stock from last 5 days at a interval of 1 day\n",
        "        You should use only one input\n",
        "        You should always input the only the ticker symbol recognized by the brapi finance. For example the string petr4 is a valid input\n",
        "        \"\"\",\n",
        "    func=get_current_stock_price\n",
        ")\n",
        "\n",
        "tools = [get_current_stock_price]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoNeDpqZ1rg7"
      },
      "source": [
        "Aqui inicializaremos o agente. Não estamos persistindo histórico, por questões de prompt mesmo. Contudo, é completamente factível o uso. No caso abaixo, caso haja várias funções a serem utilizadas, o sistema atribui um caminho linear a cada uma delas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4NR9eqF1rhD"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent\n",
        "agent = initialize_agent(\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLcEAadZ1rhE"
      },
      "source": [
        "#### Tradutor\n",
        "\n",
        "Agora vamos utilizar o **GoogleTranslator** da biblioteca **deep_translator** para executar a tarefa. Como o modelo foi treinado, originalmente, em inglês, sua performance perante a lingua e semântica também é melhor nesta língua. Portanto, para garantir boa qualidade, iremos utilizar um tradutor de português para inglês."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG7Wh9FB1rhE"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "translator_en_pt = GoogleTranslator(source='en',target='pt')\n",
        "translator_pt_en = GoogleTranslator(source='pt',target='en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03wde1gJ1rhE"
      },
      "source": [
        "#### Função responsável por orquestrar a tradução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW--6qm-1rhE"
      },
      "outputs": [],
      "source": [
        "def financial_qa(input_text):\n",
        "    input_text = translator_pt_en.translate(input_text)\n",
        "    response = agent.run(input_text)\n",
        "    response = translator_en_pt.translate(response)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ56Pcba1rhF"
      },
      "source": [
        "Aqui podemos ver o passo a passo que o agente realiza para devolver a melhor resposta. Infelizmente nem tudo é de primeira, porém o Mistral 7B foi o que melhor se comportou perante prompts mais genéricos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5bGBdrS1rhF",
        "outputId": "d6220f2a-9e80-418f-8aab-081ddfabdf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I need to get the current stock price for the given ticker symbol\n",
            "Action: get_current_stock_price\n",
            "Action Input: petr4"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    9183.80 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    35 runs   (    0.26 ms per token,  3869.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =    8475.14 ms /    35 runs   (  242.15 ms per token,     4.13 tokens per second)\n",
            "llama_print_timings:       total time =    8558.92 ms\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to get the current stock price for the given ticker symbol\n",
            "Action: get_current_stock_price\n",
            "Action Input: petr4\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{\"results\": [{\"symbol\": \"PETR4\", \"currency\": \"BRL\", \"twoHundredDayAverage\": 30.27485, \"twoHundredDayAverageChange\": 4.08515, \"twoHundredDayAverageChangePercent\": 0.13493542, \"marketCap\": 461959920000, \"shortName\": \"PETROBRAS   PN      N2\", \"longName\": \"Petr\\u00f3leo Brasileiro S.A. - Petrobras\", \"regularMarketChange\": -0.13000107, \"regularMarketChangePercent\": -0.37692392, \"regularMarketTime\": \"2023-12-11 21:07:56+00\", \"regularMarketPrice\": 34.36, \"regularMarketDayHigh\": 0, \"regularMarketDayRange\": \"0.0 - 0.0\", \"regularMarketDayLow\": 0, \"regularMarketVolume\": 0, \"regularMarketPreviousClose\": 34.49, \"regularMarketOpen\": 0, \"averageDailyVolume3Month\": 50709248, \"averageDailyVolume10Day\": 46124460, \"fiftyTwoWeekLowChange\": 34.36, \"fiftyTwoWeekLowChangePercent\": null, \"fiftyTwoWeekRange\": \"0.0 - 38.86\", \"fiftyTwoWeekHighChange\": -4.5, \"fiftyTwoWeekHighChangePercent\": -0.115800306, \"fiftyTwoWeekLow\": 0, \"fiftyTwoWeekHigh\": 38.86, \"priceEarnings\": 3.27334746, \"earningsPerShare\": 10.4968915, \"logourl\": \"https://s3-symbol-logo.tradingview.com/brasileiro-petrobras--big.svg\", \"updatedAt\": \"2023-12-12 11:54:51.44+00\", \"usedInterval\": \"1d\", \"usedRange\": \"5d\", \"historicalDataPrice\": [{\"date\": 1701781200, \"open\": 34.92, \"high\": 35.17, \"low\": 34.68, \"close\": 34.75, \"volume\": 43234200, \"adjustedClose\": 34.75}, {\"date\": 1701867600, \"open\": 34.55, \"high\": 34.8, \"low\": 33.5, \"close\": 33.5, \"volume\": 64179200, \"adjustedClose\": 33.5}, {\"date\": 1701954000, \"open\": 33.65, \"high\": 34.18, \"low\": 33.04, \"close\": 33.42, \"volume\": 64723900, \"adjustedClose\": 33.42}, {\"date\": 1702040400, \"open\": 33.71, \"high\": 34.54, \"low\": 33.48, \"close\": 34.49, \"volume\": 53290700, \"adjustedClose\": 34.49}, {\"date\": 1702299600, \"open\": 34.46, \"high\": 34.69, \"low\": 34.24, \"close\": 34.36, \"volume\": 30613300, \"adjustedClose\": 34.36}], \"validRanges\": [\"1d\", \"5d\", \"7d\", \"1mo\", \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", \"max\"], \"validIntervals\": [\"1m\", \"2m\", \"5m\", \"15m\", \"30m\", \"60m\", \"90m\", \"1h\", \"1d\", \"5d\", \"1wk\", \"1mo\", \"3mo\"]}], \"requestedAt\": \"2023-12-12T11:55:54.226Z\", \"took\": \"11ms\"}\u001b[0m\n",
            "Thought: I now know the current price of the petr4 asset in Brazilian Real\n",
            "Final Answer: 34.36\u001b[32;1m\u001b[1;3m I now know the current price of the petr4 asset in Brazilian Real\n",
            "Final Answer: 34.36\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Resposta: \n",
            "34,36\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    9183.80 ms\n",
            "llama_print_timings:      sample time =       6.95 ms /    27 runs   (    0.26 ms per token,  3883.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =   49613.62 ms /  1114 tokens (   44.54 ms per token,    22.45 tokens per second)\n",
            "llama_print_timings:        eval time =    6498.98 ms /    26 runs   (  249.96 ms per token,     4.00 tokens per second)\n",
            "llama_print_timings:       total time =   56179.44 ms\n"
          ]
        }
      ],
      "source": [
        "response = financial_qa(\"Qual o preço atual do ativo petr4 em Real brasileiro\")\n",
        "print(f\"Resposta: \\n{response}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TZvOvM61rhF",
        "outputId": "aff325cc-322d-455e-8239-26258057e12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I need to check the performance of RADL3 stock from last 5 days.\n",
            "Action: get_current_stock_price\n",
            "Action Input: RADL3"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    9183.80 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    40 runs   (    0.25 ms per token,  3947.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =    9644.45 ms /    40 runs   (  241.11 ms per token,     4.15 tokens per second)\n",
            "llama_print_timings:       total time =    9738.84 ms\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to check the performance of RADL3 stock from last 5 days.\n",
            "Action: get_current_stock_price\n",
            "Action Input: RADL3\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{\"results\": [{\"symbol\": \"RADL3\", \"currency\": \"BRL\", \"twoHundredDayAverage\": 26.879292, \"twoHundredDayAverageChange\": 1.3707085, \"twoHundredDayAverageChangePercent\": 0.050994962, \"marketCap\": 48431235000, \"shortName\": \"RAIADROGASILON  EJ  NM\", \"longName\": \"Raia Drogasil S.A.\", \"regularMarketChange\": 0.059999466, \"regularMarketChangePercent\": 0.21283953, \"regularMarketTime\": \"2023-12-11 21:07:00+00\", \"regularMarketPrice\": 28.25, \"regularMarketDayHigh\": 0, \"regularMarketDayRange\": \"0.0 - 0.0\", \"regularMarketDayLow\": 0, \"regularMarketVolume\": 0, \"regularMarketPreviousClose\": 28.19, \"regularMarketOpen\": 0, \"averageDailyVolume3Month\": 5936357, \"averageDailyVolume10Day\": 6181290, \"fiftyTwoWeekLowChange\": 28.25, \"fiftyTwoWeekLowChangePercent\": null, \"fiftyTwoWeekRange\": \"0.0 - 29.9\", \"fiftyTwoWeekHighChange\": -1.6499996, \"fiftyTwoWeekHighChangePercent\": -0.055183936, \"fiftyTwoWeekLow\": 0, \"fiftyTwoWeekHigh\": 29.9, \"priceEarnings\": 43.94835096, \"earningsPerShare\": 0.6343358, \"logourl\": \"https://s3-symbol-logo.tradingview.com/raiadrogasilon--big.svg\", \"updatedAt\": \"2023-12-12 11:55:06.07+00\", \"usedInterval\": \"1d\", \"usedRange\": \"5d\", \"historicalDataPrice\": [{\"date\": 1701781200, \"open\": 28.35, \"high\": 28.96, \"low\": 28.35, \"close\": 28.57, \"volume\": 4504900, \"adjustedClose\": 28.5193}, {\"date\": 1701867600, \"open\": 28.67, \"high\": 28.73, \"low\": 28.27, \"close\": 28.63, \"volume\": 3479000, \"adjustedClose\": 28.5792}, {\"date\": 1701954000, \"open\": 28.69, \"high\": 28.84, \"low\": 28.09, \"close\": 28.24, \"volume\": 3952500, \"adjustedClose\": 28.24}, {\"date\": 1702040400, \"open\": 28.36, \"high\": 28.52, \"low\": 28.05, \"close\": 28.19, \"volume\": 3065800, \"adjustedClose\": 28.19}, {\"date\": 1702299600, \"open\": 28.19, \"high\": 28.5, \"low\": 28.02, \"close\": 28.25, \"volume\": 3384600, \"adjustedClose\": 28.25}], \"validRanges\": [\"1d\", \"5d\", \"7d\", \"1mo\", \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", \"max\"], \"validIntervals\": [\"1m\", \"2m\", \"5m\", \"15m\", \"30m\", \"60m\", \"90m\", \"1h\", \"1d\", \"5d\", \"1wk\", \"1mo\", \"3mo\"]}], \"requestedAt\": \"2023-12-12T11:58:42.156Z\", \"took\": \"10ms\"}\u001b[0m\n",
            "Thought: I got the closing price of RADL3 stock for the last 5 days\n",
            "Final Answer: The closing prices for RADL3 stock from December 7 to December 11 are, respectively, 28.57, 28.63, 28.24, 28.19, and 28.25."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    9183.80 ms\n",
            "llama_print_timings:      sample time =      20.77 ms /    80 runs   (    0.26 ms per token,  3851.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =   50682.85 ms /  1113 tokens (   45.54 ms per token,    21.96 tokens per second)\n",
            "llama_print_timings:        eval time =   20267.84 ms /    79 runs   (  256.55 ms per token,     3.90 tokens per second)\n",
            "llama_print_timings:       total time =   71152.68 ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m I got the closing price of RADL3 stock for the last 5 days\n",
            "Final Answer: The closing prices for RADL3 stock from December 7 to December 11 are, respectively, 28.57, 28.63, 28.24, 28.19, and 28.25.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Resposta: \n",
            "Os preços de fechamento das ações RADL3 de 7 a 11 de dezembro são, respectivamente, 28,57, 28,63, 28,24, 28,19 e 28,25.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = financial_qa(\"Qual é o preço de fechamento dos 5 ultimos dias da ação RADL3?\")\n",
        "print(f\"Resposta: \\n{response}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8YCYsmI1rhF",
        "outputId": "e911a362-b42e-4dc9-a116-60d00f8800c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I need to get the stock price for ALZR11 over time and find when it closed at its highest point.\n",
            "Action: get_current_stock_price\n",
            "Action Input: \"ALZR11\""
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    9183.80 ms\n",
            "llama_print_timings:      sample time =      13.18 ms /    50 runs   (    0.26 ms per token,  3795.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:        eval time =   12030.36 ms /    50 runs   (  240.61 ms per token,     4.16 tokens per second)\n",
            "llama_print_timings:       total time =   12152.42 ms\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to get the stock price for ALZR11 over time and find when it closed at its highest point.\n",
            "Action: get_current_stock_price\n",
            "Action Input: \"ALZR11\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{\"results\": [{\"symbol\": \"ALZR11\", \"currency\": \"BRL\", \"twoHundredDayAverage\": 114.33903, \"twoHundredDayAverageChange\": 1.4109726, \"twoHundredDayAverageChangePercent\": 0.012340253, \"marketCap\": null, \"shortName\": \"FII ALIANZA CI\", \"longName\": \"Alianza Trust Renda Imobiliaria Fundo Investimento Imobiliario\", \"regularMarketChange\": 0.41000366, \"regularMarketChangePercent\": 0.35547397, \"regularMarketTime\": \"2023-12-11 20:53:19+00\", \"regularMarketPrice\": 115.75, \"regularMarketDayHigh\": 0, \"regularMarketDayRange\": \"0.0 - 0.0\", \"regularMarketDayLow\": 0, \"regularMarketVolume\": 0, \"regularMarketPreviousClose\": 115.34, \"regularMarketOpen\": 0, \"averageDailyVolume3Month\": 16647, \"averageDailyVolume10Day\": 16120, \"fiftyTwoWeekLowChange\": 115.75, \"fiftyTwoWeekLowChangePercent\": null, \"fiftyTwoWeekRange\": \"0.0 - 118.7\", \"fiftyTwoWeekHighChange\": -2.949997, \"fiftyTwoWeekHighChangePercent\": -0.024852544, \"fiftyTwoWeekLow\": 0, \"fiftyTwoWeekHigh\": 118.7, \"priceEarnings\": null, \"earningsPerShare\": null, \"logourl\": \"https://s3-symbol-logo.tradingview.com/fii--big.svg\", \"updatedAt\": \"2023-12-12 12:00:06.185+00\", \"usedInterval\": \"1d\", \"usedRange\": \"5d\", \"historicalDataPrice\": [{\"date\": 1701781200, \"open\": 114.03, \"high\": 114.74, \"low\": 114.03, \"close\": 114.58, \"volume\": 12288, \"adjustedClose\": 114.58}, {\"date\": 1701867600, \"open\": 114.58, \"high\": 115, \"low\": 114.56, \"close\": 114.98, \"volume\": 13760, \"adjustedClose\": 114.98}, {\"date\": 1701954000, \"open\": 114.9, \"high\": 115.25, \"low\": 114.68, \"close\": 115.25, \"volume\": 13012, \"adjustedClose\": 115.25}, {\"date\": 1702040400, \"open\": 115.25, \"high\": 115.37, \"low\": 114.93, \"close\": 115.34, \"volume\": 10819, \"adjustedClose\": 115.34}, {\"date\": 1702299600, \"open\": 115.34, \"high\": 115.92, \"low\": 115.21, \"close\": 115.75, \"volume\": 16584, \"adjustedClose\": 115.75}], \"validRanges\": [\"1d\", \"5d\", \"7d\", \"1mo\", \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", \"max\"], \"validIntervals\": [\"1m\", \"2m\", \"5m\", \"15m\", \"30m\", \"60m\", \"90m\", \"1h\", \"1d\", \"5d\", \"1wk\", \"1mo\", \"3mo\"]}], \"requestedAt\": \"2023-12-12T12:02:03.627Z\", \"took\": \"23ms\"}\u001b[0m\n",
            "Thought: The stock price is the highest on 12/11/23 at $115.75\n",
            "Final Answer: ALZR11 had its best closing on December 11th"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    9183.80 ms\n",
            "llama_print_timings:      sample time =      11.16 ms /    44 runs   (    0.25 ms per token,  3943.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =   48845.63 ms /  1091 tokens (   44.77 ms per token,    22.34 tokens per second)\n",
            "llama_print_timings:        eval time =   10871.05 ms /    43 runs   (  252.82 ms per token,     3.96 tokens per second)\n",
            "llama_print_timings:       total time =   59826.59 ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m The stock price is the highest on 12/11/23 at $115.75\n",
            "Final Answer: ALZR11 had its best closing on December 11th\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Resposta: \n",
            "ALZR11 teve seu melhor fechamento no dia 11 de dezembro\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = financial_qa(\"Qual foi o dia em que o fundo imobiliário ALZR11 obteve o melhor fechamento?\")\n",
        "print(f\"Resposta: \\n{response}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wl8hqCc1rhG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}